### Der KI-Testfall

Das rekursive Modell macht eine konkrete Vorhersage über künstliche Intelligenz: Systeme mit hohem Wissen und hoher Leistung, aber ohne Motivation sollten die selbstgesteuerte Entwicklung, die menschliche Intelligenz auszeichnet, nicht zeigen. Und genau das beobachtet man.

Heutige große Sprachmodelle verfügen über enormes Wissen (trainiert auf Billionen von Tokens), hohe Leistung (Milliarden von Parametern) — und keinerlei Motivation. Sie verarbeiten, was man ihnen gibt, und produzieren, worum man sie bittet. Zwischen Anfragen tun sie nichts. Sie suchen nicht nach Wissenslücken. Sie üben keine Fähigkeiten. Sie grübeln nicht über Probleme. Ihre "Intelligenz" ist vollkommen statisch — durch Training festgelegt, ohne inneren Antrieb, sie zu erweitern.

Selbst die fortschrittlichsten Reasoning-Modelle — fähig, mathematische Wettbewerbsaufgaben zu lösen — zeigen genau dieses Muster. Sie lösen außerordentliche Probleme *auf Aufforderung*, suchen aber nicht eigenständig nach Problemen, steuern ihr Lernen nicht selbst und brauchen externe Hilfsstrukturen als Ersatz für die fehlende Motivationskomponente. Leistung und Wissen lassen sich beliebig skalieren: ohne Motivation erhält sich der Kreislauf nicht von allein.

Das liegt nicht bloß daran, dass diese Systeme nicht zur Selbstverbesserung entworfen wurden. Schon diese Feststellung gibt den Punkt zu: Ein System zu entwerfen, das sich selbst verbessert, erfordert die Entwicklung eines funktionalen Analogons von Motivation. Solange KI-Systeme das nicht haben, bleiben sie Werkzeuge, die man benutzt — keine Agenten, die sich entwickeln.

### Die Verbindung zum Bewusstsein

Hier schließt sich der Kreis zurück zur Vier-Modelle-Theorie im Zentrum dieses Buches. Der rekursive Intelligenzkreislauf *profitiert* nicht bloß *von* Bewusstsein — er *setzt es voraus*.

Der Kreislauf hängt von einer bestimmten kognitiven Fähigkeit ab: *kognitives Lernen* — die Fähigkeit, aus einzelnen Beobachtungen allgemeine Theorien abzuleiten, im Unterschied zu bloßem Verstärkungslernen (Reiz-Reaktions-Konditionierung). Verstärkungslernen bringt einem bei, einen heißen Ofen durch Schmerz zu meiden. Kognitives Lernen ermöglicht es, zu beobachten, wie jemand anderes einen heißen Ofen berührt, und zu verallgemeinern: "Heiße Dinge brennen. Heiße Dinge nicht anfassen." Der entscheidende Unterschied ist die Fähigkeit, Szenarien aus der Drittperson-Perspektive zu simulieren — sich selbst als Objekt in der Welt zu modellieren und durchzuspielen, was passieren würde, wenn man verschiedene Dinge täte.

Genau das leisten das Explizite Weltmodell und das Explizite Selbstmodell. Bewusstsein — die Fähigkeit, eine Selbstsimulation zu erzeugen und laufen zu lassen — ist das *Substrat*, auf dem der rekursive Intelligenzkreislauf operiert. Ohne explizite Modelle gibt es Verstärkungslernen: funktioniert, akkumuliert sich aber nicht. Mit expliziten Modellen gibt es kognitives Lernen, das den rekursiven Kreislauf speist und sich über ein ganzes Leben aufbaut.

Deshalb bildet der Gradient tierischer Intelligenz aus Kapitel 10 sich auf den Bewusstseins-Gradienten ab. Leistungsfähigere Selbstmodelle ermöglichen leistungsfähigere rekursive Kreisläufe. Ein Hund mit einem relativ einfachen Selbstmodell durchläuft eine begrenzte Version des Kreislaufs — er kann bis zu einem gewissen Grad aus Beobachtung lernen, aber sein kognitives Lernen ist durch den Detailreichtum seiner expliziten Modelle begrenzt. Ein Schimpanse mit einem reicheren Selbstmodell durchläuft einen leistungsfähigeren Kreislauf. Ein Mensch mit der vollen Vier-Modelle-Architektur lässt den Kreislauf bei maximaler Kapazität laufen — und die Ergebnisse sind Sprache, Kultur, Wissenschaft und alles andere, was menschliche Intelligenz von tierischer Kognition unterscheidet.

### Die Erlernbarkeits-Implikation

Das rekursive Modell hat eine Konsequenz, die womöglich wichtiger ist als alle theoretischen Argumente zusammen: Es sagt vorher, dass Intelligenz zu einem großen Teil *erlernbar* ist.

Wissen ist vollständig erlernbar — das stimmt per Definition. Motivation ist weitgehend erlernbar — Jahrzehnte der Forschung zur Selbstbestimmungstheorie zeigen, dass intrinsische Motivation keine fixe Eigenschaft ist, sondern eine Reaktion auf Umgebungsbedingungen, insbesondere Autonomie, Kompetenz und Zugehörigkeit. Leistung hat eine biologische Obergrenze, aber für die überwältigende Mehrheit der Menschen ist diese Obergrenze nicht der Flaschenhals. Durchschnittliche kognitive Verarbeitungskapazität reicht mehr als aus für das, was die meisten als hochintelligentes Verhalten erkennen würden.

Die begrenzenden Faktoren sind für die meisten Menschen die meiste Zeit Motivation und operationales Wissen. Und beides lässt sich beeinflussen.

Das hat eine düstere Kehrseite. Jedes System, das systematisch Motivation in Lernenden zerstört, entwickelt Intelligenz nicht bloß nicht — es *unterdrückt* sie *aktiv*. Konventionelle Notensysteme tun genau das. Eine schlechte Note meldet nicht bloß ein Ergebnis; sie greift die Motivationskomponente an. Geringere Motivation bedeutet weniger Durchläufe des Kreislaufs. Weniger Durchläufe bedeuten langsameres Wissenswachstum. Langsameres Wachstum bedeutet schlechtere Ergebnisse bei der nächsten Prüfung. Schlechtere Ergebnisse bedeuten weitere schlechte Noten. Der Kreislauf hat sich umgekehrt: Statt Zinseszins-Wachstum steckt das Kind nun in Zinseszins-Stagnation fest. Das Notensystem produziert genau das Ergebnis, das es vorgibt, lediglich zu messen.

Das rekursive Modell sagt vorher, dass sich dieser Schaden über die Zeit akkumuliert — kein statischer Schaden, sondern beschleunigende Divergenz. Früher motivationaler Schaden sollte sich als ein Aufgehen der Entwicklungsschere zeigen, die mit jedem Jahr weiter aufgeht. Umgekehrt sollten motivationsfördernde Maßnahmen Nutzen zeigen, der sich *akkumuliert* — stärkere Effekte nach fünf Jahren als nach einem Jahr. Und tatsächlich zeigen Analysen frühkindlicher Interventionen wie dem Perry Preschool Project genau dieses Muster: Erträge, die über die Zeit wachsen, getrieben nicht durch Fortbestehen anfänglicher kognitiver Gewinne (die oft verblassen), sondern durch akkumulierende motivationale und selbstregulatorische Gewinne.

Falls es einen praktischen Schluss aus dem Intelligenzmodell gibt, dann diesen: Das Wertvollste, was ein Bildungssystem vermitteln kann, ist nicht Faktenwissen — im Zeitalter der KI sind Fakten gratis — sondern *operationales Wissen* und die Motivation, es einzusetzen. Zu lernen, wie man lernt, und lernen zu wollen — das sind die einzigen Dinge, die zu lehren sich noch lohnt.

### Die externe Abhängigkeit

Ein letzter Punkt, weil er leicht übersehen wird und wichtig ist. Der rekursive Kreislauf verstärkt sich selbst, aber er ist nicht autark. Er braucht externen Treibstoff — Informationen, Herausforderungen, Feedback, Zugang zur nächsten Wissensebene. Man stelle sich ein Kind vor, das im Alter von elf Jahren an eine Wand stößt — nicht wegen irgendeiner inneren Begrenzung, sondern weil schlicht der Vorrat an Mathematikbüchern aufgebraucht ist. Alle drei Komponenten funktionieren einwandfrei. Der Kreislauf stagniert trotzdem, weil Kreisläufe Input von außen brauchen, um weiter zu iterieren.

Das heißt: Intelligenzentwicklung hängt nicht nur von der Person ab, sondern von der Umgebung. Zugang zu Wissen, Qualität des Unterrichts, Verfügbarkeit von Mentoren, kulturelle Einstellung zum Lernen — all das nährt den Kreislauf oder lässt ihn verhungern. Das rekursive Modell erklärt, warum sozioökonomische Faktoren intellektuelle Entwicklung so stark vorhersagen: Sie bestimmen das Angebot an externem Treibstoff. Ein Kind in einem bücherreichen Zuhause mit engagierten Eltern bekommt den Kreislauf ständig gefüttert. Ein Kind in einer ressourcenarmen Umgebung bekommt ihn ausgehungert — unabhängig von der inneren Kapazität.

Intelligenz ist keine Eigenschaft, die man hat. Es ist ein Prozess, den man laufen lässt. Und ob der Prozess gut läuft, hängt von der Maschine (Leistung), der Software (Wissen), dem Fahrer (Motivation) und der Straße (der Umgebung) ab. Alle vier zählen. Jedes Modell, das eines davon weglässt, wird die Vorhersagen verfehlen.

---
