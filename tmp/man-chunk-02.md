## Kapitel 2: Die vier Modelle

Stellen wir uns vor, wir schauen auf einen Apfel.

Der Apfel liegt auf einem Tisch. Rot, rund, glänzend, etwa fünfzehn Zentimeter von der eigenen Hand entfernt. Man kann ihn sehen, weiß, was er ist, könnte die Hand ausstrecken und ihn greifen. Das scheint unkompliziert – man sieht einen Apfel.

Aber was tatsächlich passiert, ist ungleich komplizierter.

Licht, das von der Oberfläche des Apfels reflektiert wird, tritt in die Augen ein, wo es auf die Photorezeptorzellen auf den Netzhäuten trifft. Diese Zellen wandeln das Licht in elektrische Signale um. Die Signale wandern entlang der Sehnerven zum visuellen Kortex im hinteren Teil des Gehirns, wo sie durch eine Hierarchie zunehmend ausgefeilter Merkmalsdetektoren verarbeitet werden: Kanten, Orientierungen, Farben, Texturen, Formen und schließlich Objekte. Irgendwo in dieser Kaskade wird die neuronale Aktivität aktiviert, die „Apfel" entspricht. Gleichzeitig bereitet das motorische System potenzielle Aktionen vor (Greifen, Fassen), das Gedächtnissystem aktiviert Assoziationen (Geschmack, Textur, das letzte Mal, als man einen Apfel gegessen hat), und das räumliche System verfolgt die Position des Apfels relativ zum eigenen Körper.

All das passiert in weniger als einer Sekunde. Und nichts davon ist, was man *erfährt*. Man erfährt nicht Photonen, die auf Zapfenzellen treffen, oder Signale, die entlang von Axonen wandern, oder Merkmalsdetektoren, die feuern. Man erfährt *einen Apfel*. Ein einheitliches, stabiles, dreidimensionales Objekt, das in einer kohärenten räumlichen Umgebung sitzt, mit einem bestimmten Aussehen und Gefühl und Bedeutung. Was wir erfahren, ist ein *Modell* – eine Echtzeit-Simulation des Apfels, erzeugt vom Gehirn aus den Rohdaten und allem, was es zuvor über Äpfel, Objekte, Tische und Physik gelernt hat.

Wie ich in Kapitel 1 argumentiert habe, ist das unkontroverse Neurowissenschaft. Jeder Neurowissenschaftler und Philosoph der Wahrnehmung stimmt zu, dass das, was wir erfahren, ein Modell ist, nicht die Realität selbst. Der Apfel, den man sieht, ist die *beste Vermutung* des Gehirns darüber, was da draußen ist, informiert durch die Sinnesdaten, aber nicht identisch damit. (Optische Täuschungen sind der lebende Beweis: Wenn eine Illusion zusammenbricht – wenn man sie plötzlich auf beide Weisen sieht – erwischt man die Simulation auf frischer Tat. Die Realität wurde nie direkt gesehen. Es war immer das Modell. Die Illusion hat es nur offensichtlich gemacht.)

Aber hier beginnt meine Theorie: Das Gehirn modelliert nicht nur den Apfel. Es modelliert *einen selbst, wie man den Apfel anschaut*. Und es ist dieses zweite Modell (das Modell des Selbst), das Informationsverarbeitung in Bewusstsein verwandelt.

### Die vier Repräsentationen des Gehirns

![Die Real/Virtuell-Trennung](../figures/figure2-real-virtual-split-bw.png)

*Die Real/Virtuell-Trennung. Das Substrat (reale Seite) speichert Wissen in synaptischen Gewichten – physikalisch, strukturell, unbewusst. Die Simulation (virtuelle Seite) erzeugt Erfahrung in Echtzeit – flüchtig, dynamisch, bewusst.*

Schon einfache neuronale Netzwerke mit nur drei Schichten können lernen, ihre Eingabe zu modellieren – zeigt man ihnen genug Beispiele, bauen sie interne Repräsentationen der Muster auf, denen sie begegnen. Das Gehirn macht genau das, aber in einem weitaus reicheren Maßstab. Es baut nicht ein Modell; es baut viele, die alles abdecken vom Sehfeld bis zur Position der Gliedmaßen, vom Klang einer Stimme bis zum Druck der Füße auf dem Boden. Diese Modelle umfassen sowohl die Welt außerhalb *als auch* den eigenen Körper und verknüpfen alle verfügbaren sensorischen Eingaben zu kohärenten Repräsentationen.

Die Neurowissenschaft kennt diese Modelle seit über einem Jahrhundert. Im motorischen Kortex und im somatosensorischen Kortex ist der Körper buchstäblich als verzerrte Karte dargestellt – Hände und Lippen grotesk vergrößert, weil sie mehr Nervenenden haben, Rumpf und Beine zu Splittern komprimiert. Diese kortikalen Karten, *Homunculi* genannt, wurden erstmals von Wilder Penfield in den 1930er Jahren durch direkte elektrische Stimulation während Hirnoperationen kartiert. Sie sind nur die anschaulichsten Beispiele; das Gehirn unterhält ähnliche Karten und Modelle in seiner gesamten Architektur. (Siehe Anhang A für mehr zur kortikalen Organisation.)

![Penfields kortikaler Homunculus – kortikale Fläche, die jeder Körperregion gewidmet ist](../figures/book/homunculi.en.png)

*Penfields kortikaler Homunculus. Der somatosensorische Kortex widmet Händen, Lippen und Zunge dramatisch mehr Fläche als dem gesamten Rumpf – eine verzerrte Körperkarte, die die Dichte der Nervenenden widerspiegelt, nicht die Größe der Körperteile.*

Ich nenne diese die **impliziten Modelle**: das Implizite Weltmodell (IWM) und das Implizite Selbstmodell (ISM). Sie sind in der Struktur des Gehirns gespeichert – in den Stärken synaptischer Verbindungen, der Architektur neuronaler Schaltkreise, dem akkumulierten Lernen eines Lebens. Sie sind die Festplatte des Gehirns. Sie werden nie direkt erfahren, nicht mehr als das Silizium im eigenen Handy. Aber sie kodieren alles, was das Gehirn über die Welt und über einen selbst weiß.

Nun die Schlüsseleinsicht. Diese impliziten Modelle sitzen nicht einfach nur da. Sie *erzeugen* etwas. In der Technik ist ein **digitaler Zwilling** eine Echtzeit-virtuelle Replik eines physischen Systems (ein Düsentriebwerk, ein Stromnetz, eine Fabrikhalle), kontinuierlich aktualisiert mit Sensordaten, damit Ingenieure das System überwachen und mit ihm interagieren können, ohne es direkt zu berühren. Die impliziten Modelle tun genau das. Sie produzieren eine Echtzeit-virtuelle Simulation der Welt und eine Echtzeit-virtuelle Simulation von einem selbst. Das sind die **expliziten Modelle**: das Explizite Weltmodell (EWM) und das Explizite Selbstmodell (ESM). Alles, was man sieht, hört, fühlt und denkt, geschieht innerhalb dieser Simulationen, nicht in der Welt selbst.

Zwei Gruppen von Modellen (implizit und explizit), jede mit sowohl einem Weltmodell als auch einem Selbstmodell. Vier Modelle insgesamt, und mit ihnen eine Sprache, um darüber zu sprechen, was Bewusstsein tatsächlich tut. (Eine Anmerkung für Neurowissenschaftler und technisch versierte Leser: Die Zahl „vier" ist ein prinzipielles Minimum, keine wörtliche Zählung dessen, was das Gehirn unterhält. Wer das beunruhigend findet, lese bitte Anhang E, bevor es weitergeht – er adressiert dies direkt.)

Aber wo laufen diese Modelle? Das Gehirn nutzt mindestens fünf Ebenen der Informationsverarbeitung, aufeinander gestapelt. Die Simulation (die bewusste Erfahrung) läuft ganz oben.

### Fünf verschachtelte Systeme

![Fünf Ebenen der Gehirnorganisation – Bewusstsein existiert nur auf der virtuellen Ebene](../figures/figure-five-layer-stack-bw.png)

*Fünf Ebenen der Gehirnorganisation. Jede Ebene superveniert auf („läuft auf") der darunter liegenden. Bewusstsein existiert nur auf der obersten virtuellen Ebene, wo die expliziten Modelle phänomenale Erfahrung erzeugen.*

Das Gehirn lässt sich als fünf verschiedene Organisationsebenen denken, gestapelt wie russische Puppen:

**Physikalisch.** Ganz unten die rohe Materie: Atome, Moleküle, das physische Substrat des Gehirns selbst. Das ist die Chemie – der Kohlenstoff, Wasserstoff, Stickstoff, Sauerstoff, die das Gewebe bilden. Inerte Materie, die den Gesetzen der Thermodynamik gehorcht. Nichts Bewusstes lebt hier.

**Elektrochemisch.** Eine Ebene höher: neuronale Signalübertragung. Aktionspotenziale rasen Axone hinunter, Neurotransmitter überfluten Synapsen, Ionen fließen durch Kanäle. Das ist die elektrische und chemische Aktivität, die sich jeder vorstellt beim Gedanken „Gehirn tut etwas". Die Ebene, wo Neuronen feuern. Immer noch keine Erfahrung, aber jetzt gibt es Informationsübertragung.

**Proteomisch.** Als Nächstes: Proteinstrukturen und molekulare Maschinerie. Synaptische Gewichte werden hier gespeichert – die physischen Stärken der Verbindungen zwischen Neuronen. Rezeptoren auf Zellmembranen, Enzyme, die Plastizität regulieren, das molekulare Gerüst, das bestimmt, welche Synapsen stärker werden und welche schwächer. Das ist die „Hardware" des Lernens. Wer eine Fähigkeit übt und besser wird, verändert die proteomische Schicht. Immer noch unbewusst, aber jetzt gibt es Gedächtnis.

**Topologisch.** Noch höher: Netzwerkarchitektur. Die Muster der Konnektivität, welche Neuronen mit welchen verbunden sind, wie dicht, in welchen Konfigurationen. Hier leben Brodmann-Areale, hier leben kortikale Säulen, hier existiert die großräumige Struktur von „visueller Kortex spricht mit motorischem Kortex". Es ist der Schaltplan. Ändert man diese Ebene, ändert sich, welche Arten von Verarbeitung das System leisten kann. Hier werden die impliziten Modelle (das IWM und ISM) gespeichert. Immer noch unbewusst. Aber jetzt gibt es Wissen.

**Virtuell.** Ganz oben: die simulierte Welt. Der kortikale Automat – das dynamische Muster elektrischer Aktivität, das über das Netzwerk tanzt, Informationen integriert, Vorhersagen generiert, die Modelle in Echtzeit laufen lässt. Hier lebt die bewusste Erfahrung. Die expliziten Modelle (das EWM und ESM) existieren hier und nur hier. Das ist die einzige Ebene, die sich nach etwas anfühlt.

Jede Ebene superveniert auf der darunter liegenden, hat aber ihre eigene Dynamik. Ohne physische Materie keine elektrochemische Signalübertragung, ohne Chemie keine Proteinstrukturen, ohne Synapsen keine Netzwerktopologie, und ohne ein Netzwerk keine Simulation, die darauf laufen könnte. Aber jede Ebene hat Eigenschaften, die die niedrigeren Ebenen nicht haben. Eine Synapse ist nicht „über" irgendetwas – sie ist nur eine Verbindung. Ein Netzwerk von Synapsen *ist* über etwas: es repräsentiert ein Gesicht, ein Wort, eine Erinnerung. Und die Simulation, die auf diesem Netzwerk läuft? Da wird aus „über" „Erfahrung".

Diese Fünf-Ebenen-Hierarchie löst ein Problem, das fast jeden stolpern lässt, der diese Theorie zum ersten Mal hört: „Wenn Bewusstsein virtuell ist, worauf läuft es?" Die Antwort: Es läuft auf der topologischen Ebene (dem Netzwerk), die in der proteomischen Ebene (synaptische Gewichte) implementiert ist, die auf der elektrochemischen Ebene (neuronales Feuern) läuft, die in der physischen Ebene (Materie) existiert. Bewusstsein ist nicht weniger real, weil es virtuell ist – es ist nur real *auf einer anderen Ebene* als Neuronen real sind. Der Berg im Videospiel ist real auf der Spielebene, auch wenn er „nur" Transistoren auf der Hardware-Ebene ist. Gleiches Prinzip.

Ich werde im Laufe des Buches auf diese Hierarchie zurückkommen, besonders wenn wir in Kapitel 6 über Psychedelika sprechen – weil Drogen nicht alle fünf Ebenen gleich treffen. Einige zielen auf die elektrochemische Ebene (Veränderung der Neurotransmitter-Dynamik), einige zielen auf die proteomische Ebene (Veränderung der Rezeptorexpression), und die Effekte wellen sich auf vorhersagbare Weise zur virtuellen Ebene hoch. Die Hierarchie ist nicht nur konzeptuell. Sie ist mechanistisch real und leistet Erklärungsarbeit.

Nun zu den vier Modellen.

**Das Implizite Weltmodell (IWM)** ist alles, was man über die Welt weiß. Nicht, woran man gerade denkt – alles, woran man *denken könnte*. Die Gesetze der Physik (fallende Objekte fallen, das wissen wir). Das Layout der eigenen Wohnung (im Dunkeln lässt sich darin navigieren). Die Grammatik der Muttersprache (ein Satz lässt sich als grammatisch oder ungrammatisch beurteilen, ohne die Regeln zu kennen). Die Gesichter aller, die man jemals gekannt hat. Der Geschmack von Schokolade. Das Geräusch von Regen.

All dieses Wissen ist in den synaptischen Verbindungen des Gehirns gespeichert – den Stärken der Verbindungen zwischen Neuronen. Es wurde über das ganze Leben durch Erfahrung und Lernen aufgebaut. Und es ist nie, niemals direkt bewusst. In die eigenen neuronalen Verbindungen lässt sich nicht introspizieren. Die eigenen Synapsen lassen sich nicht fühlen. Das Implizite Weltmodell ist wie eine riesige Bibliothek, die man nie betritt – man liest nur die Bücher, die sie einem an den Schreibtisch schickt.

**Das Implizite Selbstmodell (ISM)** ist alles, was man über sich selbst weiß. Das Körperschema – die unbewusste Repräsentation, wo die Gliedmaßen sind, wie groß sie sind, wie sie sich bewegen. Die motorischen Fähigkeiten (Fahrradfahren, Tippen, ein Instrument spielen). Die Persönlichkeitsmerkmale, sozialen Fähigkeiten, emotionalen Muster, Gewohnheiten. Die autobiographische Gedächtnisstruktur (das Gerüst, das die Erinnerungen zu einer Lebensgeschichte organisiert).

Wie das Weltmodell ist das Selbstmodell in synaptischen Gewichten gespeichert und nie direkt bewusst. Man erfährt nicht das Körperschema; man erfährt den Körper, den das Schema erzeugt. Man erfährt nicht die Persönlichkeit; man erfährt die Gedanken und Gefühle, die sie produziert. Das Implizite Selbstmodell ist die Hinterbühnen-Crew – essenziell für die Aufführung, aber nie vom Publikum gesehen.

**Das Explizite Weltmodell (EWM)** ist die Welt, die man tatsächlich erfährt. Gerade jetzt. Der Raum, in dem man sich befindet, die Geräusche, die man hört, das Gewicht dieses Buches in den Händen (oder das Leuchten des Bildschirms, auf dem man es liest). Das ist die Simulation – die Echtzeit-virtuelle Realität des Gehirns, erzeugt aus dem Impliziten Weltmodell plus aktueller sensorischer Eingabe. Sie ist lebendig, detailliert und nahtlos überzeugend. Man wird das ganze Leben darin leben und nie hinaustreten.

**Das Explizite Selbstmodell (ESM)** ist das *Selbst*. Das Gefühl, ein Subjekt zu sein. Das Gefühl von „Ich" – derjenige, der sieht, hört, denkt und entscheidet. Auch das ist eine Simulation: ein Echtzeit-Modell, erzeugt aus dem Impliziten Selbstmodell plus aktuellen Körpersignalen. Es ist der Charakter, den das Gehirn erschafft, um seine virtuelle Welt zu bewohnen. Man IST der Charakter, den das Gehirn erschafft, um seine virtuelle Welt zu bewohnen.

### Die reale Seite und die virtuelle Seite

![Die Vier-Modelle-Architektur des Bewusstseins](../figures/figure1-four-model-architecture-bw.png)

*Die Vier-Modelle-Architektur. Das Gehirn unterhält zwei Arten von Modell (eines von der Welt, eines vom Selbst), jedes in zwei Modi: implizit (in der Struktur des Gehirns gespeichert) und explizit (aktiv laufend als Echtzeit-Simulation). Bewusstsein lebt in den expliziten Modellen.*

Die vier Modelle teilen sich in zwei Seiten, und diese Teilung ist das Fundament von allem, was folgt.

Die **reale Seite** (die zwei impliziten Modelle) ist physikalisch, strukturell und relativ starr (durch Lernen angepasst). Es ist das gespeicherte Wissen des Gehirns: synaptische Gewichte, Netzwerkverbindungen, Rezeptorkonfigurationen. Man stelle es sich vor als alles, was das Gehirn *gelernt hat* – kristallisiert in die physische Struktur des Gewebes selbst. Es hat keine Erfahrung. Das Feuern einer Synapse wird nicht mehr „erfahren" als Wasser, das durch ein Rohr fließt. Die reale Seite ist Licht aus.

Etwas, das es wert ist zu betonen: Die reale Seite ist das, was die Neurowissenschaft bereits studiert. Wenn ein Forscher jemanden in einen fMRT-Scanner steckt, schaut er auf die reale Seite – Feuermuster, Konnektivität, Blutfluss zu verschiedenen Regionen. Wenn ein Neurochirurg einen kortikalen Bereich stimuliert und beobachtet, was passiert, sondiert er die reale Seite. Die Neurowissenschaft hat dieses Territorium seit über einem Jahrhundert kartiert, und sie hat außergewöhnliche Fortschritte gemacht. Die Vier-Modelle-Theorie weist keine dieser Arbeiten zurück. Sie sagt, dass all das nur die Hälfte des Bildes beschreibt.

Die **virtuelle Seite** (die zwei expliziten Modelle) ist simuliert, flüchtig und dynamisch. Sie wird in jedem Moment neu aus der realen Seite plus aktueller Eingabe erzeugt. Man stelle es sich vor als alles, was das Gehirn *gerade mit* dem macht, was es gelernt hat – die Live-Show, nicht das gespeicherte Skript. Und es ist *alles* Erfahrung. Jeder Anblick, Klang, Gedanke, jedes Gefühl, jede Erinnerung, jeder Traum und jede Halluzination, die man jemals hatte, ist auf der virtuellen Seite aufgetreten. Die virtuelle Seite ist Licht an.

Aber hier ist der Haken: Die virtuelle Seite ist von außen unsichtbar. Selbst unsere fortschrittlichste Bildgebung des Gehirns kann sie nur indirekt erfassen. Ein fMRT zeigt, welche Hirnregionen aktiv sind – das ist die reale Seite bei der Arbeit. Um tatsächlich bewusste Erfahrung aus Gehirndaten zu *lesen*, müsste man die Programmiersprache des Gehirns entschlüsseln – verstehen, nicht nur welche Neuronen feuern, sondern was das Muster des Feuerns *bedeutet* auf der Simulationsebene. Das würde etwas wie ein vollständig simuliertes Konnektom erfordern: eine vollständige digitale Replik des Gehirns, in Software laufend, die dieselbe virtuelle Welt produziert, die das biologische Gehirn produziert.

Ich möchte ehrlich sein über das, was die Theorie gibt und nicht gibt. Die Vier-Modelle-Theorie sagt *was* die Simulation ist, *wo* sie lebt, und *warum* sie sich nach etwas anfühlt. Sie händigt nicht den Entschlüsselungsring aus. Die virtuelle Seite aus der realen Seite zu lesen, ist ein zukünftiges Forschungsprogramm – eines, das die Theorie klar definiert, aber noch nicht ausführen kann. Allerdings wird die Grundlage für dieses Programm bereits gelegt. Das Human Connectome Project und verwandte Bemühungen kartieren die Verdrahtung des Gehirns mit zunehmend feiner Auflösung. Die virtuelle Seite lässt sich noch nicht aus strukturellen Daten dekodieren, aber die strukturellen Daten kommen.

Wer wissenschaftlich denkt, sieht vielleicht schon, wohin das führt. Wenn Erfahrung nur auf der virtuellen Seite existiert, dann ist die Suche nach Erfahrung auf der realen Seite – in den Neuronen, in den Synapsen, in der physischen Maschinerie – an der völlig falschen Stelle. Es ist, als würde man nach der Handlung eines Films in den Schaltkreisen des DVD-Players suchen.

Das ist der Schlüssel. Hier ist er.

### Wie bewusst ist man?

Aber zuerst etwas, worüber man sich wahrscheinlich schon gewundert hat. Wenn Bewusstsein eine Simulation ist – ein virtuelles Selbst innerhalb einer virtuellen Welt – dann ist es keine Alles-oder-Nichts-Sache, oder? Eine Simulation kann mehr oder weniger detailliert sein. Ein Selbstmodell kann mehr oder weniger ausgereift sein. Das bedeutet, dass Bewusstsein in *Graden* kommt.

Die Vier-Modelle-Theorie bietet eine präzise Möglichkeit, über diese Grade nachzudenken. Es gibt vier abgestufte Ebenen, und jedes bewusste Geschöpf sitzt irgendwo auf dieser Leiter.

Ganz unten steht **einfaches Bewusstsein**. Das ist ein Explizites Weltmodell mit nur einem rudimentären Expliziten Selbstmodell. Das System erzeugt eine virtuelle Welt – es ist etwas wie etwas, dieses Geschöpf zu sein – aber das Selbst innerhalb dieser Welt ist kaum skizziert. Man denke an eine Maus, die durch ein Labyrinth navigiert. Sie sieht die Wände, riecht den Käse, fühlt den Boden unter ihren Pfoten. Sie hat phänomenale Erfahrung. Aber ihr Modell von *sich selbst* als das Ding, das diese Erfahrungen hat? Hauchdünn. Es gibt ein „wie es ist wie", aber fast kein „für wen es ist wie".

Eine Stufe höher: **einfach erweitertes Bewusstsein**. Jetzt wird das Selbstmodell real. Das System erfährt nicht nur – es modelliert sich selbst *als* den Erfahrenden. Es ist sich bewusst, dass es erfährt. Der Hund fühlt nicht nur Schmerz; er weiß, dass *er* Schmerzen hat. Es gibt eine Ich-Perspektive – ein echtes „Ich" im Zentrum der virtuellen Welt. Das ist Selbstbeobachtung erster Ordnung, und es ändert alles. Leiden wird hier möglich, weil Leiden ein Selbst erfordert, das weiß, dass es leidet.

Dann: **doppelt erweitertes Bewusstsein**. Selbstbeobachtung zweiter Ordnung. Das System modelliert sich selbst, sich selbst zu modellieren. Das ist Metakognition – Denken über das eigene Denken. Man liegt im Bett und fragt sich, ob die Angst vor dem morgigen Meeting rational ist oder ob man katastrophisiert. Die eigenen mentalen Zustände werden überwacht, bewertet, manchmal überschrieben. Hier lebt das meiste erwachsene menschliche Bewusstsein die meiste Zeit. Es ist die Ebene, die Therapie möglich macht, die es erlaubt zu sagen „Ich bemerke, dass ich wütend werde" anstatt nur wütend zu sein.

Und ganz oben: **dreifach erweitertes Bewusstsein**. Dritte Ordnung. Das System modelliert sich selbst, sich selbst zu modellieren, sich selbst zu modellieren. Das klingt wie ein Spiegelsaal, und das ist es auch, aber es ist ein Spiegelsaal, den es braucht, um Philosophie des Geistes zu betreiben. Um zu fragen „was ist Bewusstsein?" muss man sich selbst modellieren, die eigene Erfahrung modellieren und dann sich selbst modellieren, wie man diese Erfahrung modelliert. Es gilt, weit genug zurückzutreten, um den gesamten Apparat von außen zu sehen, obwohl man immer noch darin ist. Das ist die Voraussetzung für die Frage, die dieses Buch zu beantworten versucht. Nur Geschöpfe, die zu dreifach erweitertem Bewusstsein fähig sind, können sich fragen, warum irgendetwas sich nach irgendetwas anfühlt.

Die Auszahlung: Dieser Gradient ist nicht nur abstrakte Philosophie. Er beantwortet die Frage, die bei jeder Dinnerparty gestellt wird – „Ist mein Hund bewusst?" Die Antwort ist ja, aber weniger bewusst als wir selbst. Der Hund ist wahrscheinlich auf der einfach erweiterten Ebene. Er hat ein Selbst. Er hat Erfahrung. Er liegt nicht um 3 Uhr morgens wach und hinterfragt die Natur dieser Erfahrung. Wir werden in Kapitel 10 im Detail auf die Tierfrage zurückkommen, wo dieser Gradient echte Erklärungsarbeit leistet. Aber die Form davon ist schon erkennbar: Bewusstsein ist kein Lichtschalter. Es ist ein Dimmer.

### Warum das Gehirn die Fähigkeit zur Selbstmodellierung hat

Also haben wir festgestellt, dass Bewusstsein von diesen vier Modellen abhängt, wobei das explizite Selbstmodell die Hauptlast trägt. Aber warum hat das menschliche Gehirn diese Fähigkeit überhaupt, wenn einfachere Tiere sie nicht haben? Die Antwort verbirgt sich in Sichtweite: Die Architektur des menschlichen Kortex ist buchstäblich überdimensioniert für grundlegende Informationsverarbeitung.

Der menschliche Neokortex hat sechs Schichten. Das ist eine wohlbekannte anatomische Tatsache, nachzulesen in jedem Neurobiologie-Lehrbuch. Aber hier ist, was interessant ist: Sechs Schichten braucht es nicht, um Informationen zu verarbeiten. Drei Schichten reichen aus.

Man überlege, was ein standardmäßiges neuronales Netzwerk leisten muss. Erste Schicht: Eingabe empfangen, filtern, aufräumen. Zweite Schicht: Muster extrahieren, Merkmale erkennen, die schwere Rechenlast heben. Dritte Schicht: Ergebnisse integrieren, Entscheidungen treffen, Ausgabe produzieren. Eingabe, Verarbeitung, Ausgabe. Das ist das Grundrezept, und drei Schichten decken es ab.

Aber wir haben sechs.

Wofür sind die „extra" drei Schichten?

Sie sind dafür da, die ersten drei zu modellieren.

Ein Drei-Schichten-Netzwerk verarbeitet die Welt. Ein Sechs-Schichten-Netzwerk verarbeitet die Welt *und* beobachtet sich dabei selbst. Die zusätzlichen Schichten bieten die architektonische Kapazität für das Gehirn, nicht nur ein Modell dessen zu bauen, was da draußen ist, sondern ein Modell von sich selbst, wie es modelliert, was da draußen ist. Selbstsimulation erfordert diese Verdopplung – es braucht einen Satz von Schichten, um die Verarbeitung zu tun, und einen anderen Satz, um die Verarbeitung geschehen zu sehen.

Das ist keine Spekulation darüber, was einzelne Schichten „tun" – ich behaupte nicht, dass Schicht 4 dies tut und Schicht 5 das tut. Es ist eine Beobachtung über architektonische Kapazität. Sechs Schichten geben Raum für sowohl das implizite Weltmodell (die gelernte, unbewusste Verarbeitung) als auch das explizite Weltmodell (die Echtzeit-Simulation). Sie geben Raum für sowohl das implizite Selbstmodell (Körperschema, Motorprogramme, Persönlichkeitsstruktur) als auch das explizite Selbstmodell (das „Ich", das erlebt, einen Körper zu haben, Handlungen zu initiieren, eine Person zu sein).

Nun schaue man auf andere Tiere. Reptilien haben drei oder vier kortikale Schichten. Säugetiere haben sechs. Und unter den Säugetieren sind diejenigen mit dem dicksten, am aufwendigsten gefalteten Kortex (Primaten, Wale, Elefanten) genau diejenigen, die die reichsten Anzeichen von Selbstbewusstsein zeigen. Selbsterkennung im Spiegel, Zukunftsplanung, soziale Täuschung, Trauer. Die architektonische Kapazität verfolgt die Phänomenologie.

Der Sprung von drei auf sechs Schichten könnte ein genetischer Duplikationsunfall gewesen sein – Evolutions-Copy-Paste, das genau die Architektur produzierte, die Bewusstsein später ausnutzen würde. Reptilien-Vorfahren hatten drei kortikale Schichten. Irgendwo im Übergang zu Säugetieren verdoppelte sich diese Zahl. Die Transkriptionsfaktoren, die kortikale Schichtidentität spezifizieren (Tbr1, Satb2, Ctip2, Fezf2), haben Paraloge, die auf Genduplikationsereignisse hinweisen. Ob das ein einzelnes dramatisches Ereignis war oder eine allmähliche Ausarbeitung, bleibt umstritten, aber das Ergebnis ist klar: Säugetiere bekamen das Doppelte an Schichten, und mit ihnen die Fähigkeit zur Selbstmodellierung, die den meisten Reptilien fehlt.

Das ist die Brücke von der neuronalen Netzwerktheorie zur gelebten Erfahrung. Der menschliche Kortex ist nicht nur ein großer Mustererkenner. Es ist ein überdimensioniertes, rekursiv strukturiertes Netzwerk mit genug Schichten, um seinen eigenen Modellierungsprozess zu modellieren. Und wenn ein Netzwerk sich selbst modelliert, wie es die Welt modelliert, ist das Ergebnis – von innen betrachtet – genau das, was wir Bewusstsein nennen.

Ich sollte klarstellen: Ich behaupte nicht, dass sechs kortikale Schichten die *einzige* Architektur sind, die Bewusstsein unterstützen kann. Sie sind eine Lösung – die, die Säugetiere entwickelt haben. Aber es könnte andere geben. Der Oktopus, mit seinem radikal verteilten Nervensystem (acht semi-autonome Arme, jeder mit seinem eigenen neuronalen Verarbeitungszentrum, das etwa 40 Millionen Neuronen enthält), repräsentiert einen völlig anderen architektonischen Ansatz, der möglicherweise äquivalente Rechenleistung erreicht. Vögel bieten ein weiteres markantes Beispiel: Rabenvögel und Papageien fehlt ein geschichteter Kortex völlig, ihr Pallium ist in Kerncluster organisiert statt in Schichten, dennoch machen Krähen Werkzeuge, planen für die Zukunft und erkennen sich wohl im Spiegel. Worauf es ankommt, ist die Fähigkeit zur Selbstmodellierung, nicht der spezifische Schaltplan – jede Architektur, die eine Simulation von sich selbst laufen lassen kann, könnte im Prinzip bewusst sein. Wir werden in Kapitel 10 darauf zurückkommen.

---
## Kapitel 3: Die virtuelle Seite

Stellen wir uns vor, wir spielen ein Videospiel. Ein gutes — ein immersives Open-World-Spiel mit atemberaubender Grafik, realistischer Physik und einer fesselnden Geschichte. Man steuert eine Figur und interagiert durch diese Figur mit einer detailreich gestalteten virtuellen Welt.

Nun überlege man: Wo existiert das Spiel? Nicht auf dem Bildschirm, genau genommen — der Bildschirm zeigt nur Lichtmuster. Nicht in der Grafikkarte oder der CPU, genau genommen — diese leiten elektrische Signale durch Siliziumschaltkreise. Das Spiel existiert als ein *virtueller Prozess* — ein höherstufiges Phänomen, das aus der Aktivität der Hardware hervorgeht, aber nicht mit irgendeinem bestimmten Stück Hardware identisch ist.

Die virtuelle Welt des Spiels hat Eigenschaften, die die Hardware nicht hat. Das Spiel hat Berge, Flüsse und Städte. Die CPU hat Transistoren. Das Spiel hat einen Tag-Nacht-Zyklus. Die GPU hat Taktzyklen. Es lässt sich sinnvoll fragen „Wie hoch ist dieser Berg im Spiel?", aber es wäre absurd, auf einen Transistor zu zeigen und zu sagen „Dieser Transistor ist 3.000 Meter hoch." Die Eigenschaften des Spiels existieren auf der virtuellen Ebene, und sie sind echte Eigenschaften des Spiels, auch wenn das Spiel „nur" ein Aktivitätsmuster in der Hardware ist.

Das ist keine Metapher. So funktioniert das Gehirn.

Das Explizite Weltmodell (EWM) — die Welt, die man erlebt — ist ein virtueller Prozess, der auf neuronaler Hardware läuft, genauso wie die Spielwelt ein virtueller Prozess ist, der auf Silizium-Hardware läuft. Die erlebte Welt hat Eigenschaften (Farben, Formen, Entfernungen, Klänge), die die neuronale Hardware nicht hat (die Hardware hat Feuerraten, synaptische Stärken und Neurotransmitter-Konzentrationen). Die Eigenschaften der erlebten Welt sind *echte Eigenschaften der Simulation*, auch wenn die Simulation „nur" ein Muster neuronaler Aktivität ist.

Das Explizite Selbstmodell (ESM) — das „Ich", das die Welt erlebt — ist ebenfalls ein virtueller Prozess. Es ist so real wie die Spielfigur in der Analogie: echt existierend auf der virtuellen Ebene, wirklich Eigenschaften besitzend auf der virtuellen Ebene, aber nicht existierend auf der Hardware-Ebene.

### Warum die Analogie zusammenbricht (auf die wichtige Art)

Die Videospiel-Analogie ist nützlich, aber sie bricht an einem entscheidenden Punkt zusammen: Das Spiel hat einen *Spieler*. Es gibt jemanden außerhalb des Spiels — auf der Couch sitzend — der das Spiel erlebt. Das Spiel selbst hat keine Erfahrung. Es sind nur Lichtmuster und Code.

Die Simulation des Gehirns hat keinen externen Spieler. Niemand sitzt außerhalb des Schädels und erlebt die Simulation. Die Simulation enthält ihren eigenen Beobachter — das Explizite Selbstmodell. Die Simulation *ist* die Erfahrung, nicht etwas, das von jemand anderem erfahren wird.

Versetzen wir uns in die Position der Spielfigur. Man *ist* die Hauptfigur. Von außerhalb des Spiels sieht ein Zuschauer Pixel, die sich auf einem Bildschirm bewegen — nichts, das möglicherweise etwas fühlen könnte. Aber von innerhalb der Simulation? Die Spielwelt ist alles, was es gibt. Die Berge sind real für die Figur, das Sonnenlicht ist warm, die Gefahr ist beängstigend. Kein externer Beobachter würde je vermuten, dass dieser Haufen Code etwas fühlt, aber das liegt daran, dass sie auf die falsche Ebene schauen. Sie schauen auf die Hardware. Die Erfahrung existiert auf der Software-Ebene. Das ist meine Behauptung, und der Rest dieses Buches legt die Beweise dar.

[ABBILDUNG: SDXL/Flux — "Ego-Perspektive aus dem Inneren einer fotorealistischen virtuellen Welt, Blick auf eine lebhafte, sonnenbeschienene Landschaft mit Bergen und einem Fluss. An den Rändern des Sichtfelds löst sich die fotorealistische Szene auf und fragmentiert in leuchtende neuronale Netzwerke, synaptische Verbindungen, fließende elektrische Impulse und durchscheinende schaltkreisähnliche Muster. Der Übergang von lebhafter Realität zum neuronalen Substrat (Substrat) ist graduell und organisch und zeigt, dass die Welt und der Beobachter aus demselben gemacht sind. Volumetrisches Licht, Tiefenschärfe, kinematografische Komposition, Konzeptkunst, digitales Gemälde, 8k, hochdetailliert" — Negativ: "text, watermark, signature, blurry, low quality, cartoon, anime, extra fingers, deformed, ugly, duplicate, out of frame" — Landscape 16:9, CFG 7-8, steps 30-40. Bei Flux: negatives Prompt weglassen.]

*Die Simulation betrachtet sich selbst. Das gesamte Sichtfeld — jede Farbe, Form und Schatten — wird vom Echtzeit-Virtualmodell des Gehirns generiert. An den Rändern wird die Illusion dünner und die neuronale Maschinerie wird sichtbar. Es gibt keine Grenze zwischen dem Beobachter und dem Beobachteten. Man ist die Simulation.*

Das ist es, was Bewusstsein besonders macht und was das Schwierige Problem (Hard Problem) so unlösbar erscheinen lässt. Im Videospiel gibt es eine klare Trennung zwischen dem Spiel (virtuell, keine Erfahrung) und dem Spieler (physisch, hat Erfahrung). Im Gehirn gibt es keine Trennung. Die Simulation und der Erfahrende sind dasselbe. Das Explizite Selbstmodell beobachtet nicht das Explizite Weltmodell von außen — es ist *innerhalb* der Simulation, Teil desselben virtuellen Prozesses.

Und dieser selbstreferentielle Abschluss (die Simulation beobachtet sich selbst von innen) ist, so argumentiere ich, was wir Bewusstsein nennen. Es ist nicht etwas, das zur Simulation hinzugefügt wird. Es ist das, was die Simulation *ist*, wenn sie ein Modell von sich selbst enthält. Deshalb sage ich, Bewusstsein ist kein Ding — es ist ein Prozess. Man wird es nicht finden, indem man das Gehirn auseinandernimmt, genauso wenig wie man ein laufendes Programm findet, indem man die CPU zerlegt.

### Die Software-Eigenschaften

Wenn die virtuellen Modelle wirklich software-ähnliche Prozesse sind, die auf neuronaler Hardware laufen, dann sollten sie sich auf spezifische, testbare Weisen wie Software verhalten. Und das tun sie. Vier Eigenschaften der virtuellen Seite werden in diesem Buch immer wieder auftauchen, also seien sie hier dargelegt.

**Forking (Aufspaltung).** Ein einzelnes Substrat kann mehrere virtuelle Konfigurationen gleichzeitig laufen lassen. In Software forkt man einen Prozess und erhält zwei unabhängige Instanzen, die auf derselben Hardware laufen. Im Gehirn ist dies die Dissoziative Identitätsstörung — mehrere Selbstmodelle, jedes mit seiner eigenen Erzählung und emotionalem Profil, die abwechselnd die Kontrolle über dasselbe neuronale Substrat übernehmen. Wir werden das in Kapitel 9 sehen.

**Cloning (Klonen).** Trenne die Hardware physisch, und du erhältst degradierte, aber vollständige Kopien der Software. Schneide das Corpus callosum durch, und jede Hemisphäre läuft ihre eigene Version der Simulation — weniger leistungsfähig als das Original, aber funktional vollständig. Das ist das Split-Brain-Phänomen, ebenfalls Kapitel 9.

**Redirecting (Umleiten).** Unterbreche den normalen Input-Strom und die Simulation klinkt sich in welches Signal auch immer dominant ist. Unter Salvia divinorum überwältigt propriozeptiver Input das System und das Explizite Selbstmodell rekonfiguriert sich um Körperempfindung herum. Unter Ketamin fällt externer Input aus und die Simulation läuft auf internem Rauschen. Die virtuellen Modelle stoppen nicht — sie verarbeiten nur, was immer ihnen zugeführt wird. Kapitel 6 behandelt dies im Detail.

**Reconfiguring (Neukonfiguration).** Verändert man die Verbindungsgewichte des Substrats, ändert sich, was die virtuellen Modelle produzieren. Genau das tut Kognitive Verhaltenstherapie — systematisches Neuverkabeln des Substrats, sodass das Explizite Selbstmodell andere Erzählungen, andere emotionale Reaktionen, anderes Verhalten generiert.

Die Vier-Modelle-Theorie (VMT) macht eine spezifische Vorhersage über Therapie: Jede wirksame Behandlung muss funktionieren, indem sie die impliziten Modelle (das Substrat) so modifiziert, dass sich die expliziten Modelle (die Simulation) entsprechend verändern. Kognitive Verhaltenstherapie tut genau das. Sie identifiziert systematisch fehlangepasste Muster im ISM und verkabelt sie durch strukturierte Übung neu, wodurch sich ändert, was das ESM produziert. Deshalb hat Kognitive Verhaltenstherapie die stärkste Evidenzbasis aller Psychotherapien: Sie zielt auf die richtige Ebene ab.

Das wirft eine unbequeme Frage auf bezüglich Therapien, die ihren Mechanismus nicht in diesen Begriffen erklären können. Wenn ein therapeutischer Ansatz nicht spezifiziert, was er im Substrat verändert oder wie diese Veränderung zur Simulation propagiert, dann funktioniert er bestenfalls über einen Mechanismus, den er nicht versteht, und schlimmstenfalls funktioniert er überhaupt nicht. Die Evidenz bestätigt dies: Die Therapien mit den schwächsten Evidenzbasen sind generell jene mit den vagsten Theorien der Veränderung. Wer Therapie sucht, sollte dem Therapeuten eine einfache Frage stellen: „Was genau versuchen Sie in meinem Gehirn zu verändern, und wie?" Wer darauf keine Antwort bekommt, sollte sich überlegen, jemanden zu finden, der eine hat.

Das sind keine Metaphern. Das sind strukturelle Vorhersagen. Wenn meine Theorie falsch ist und die virtuellen Modelle *nicht* software-ähnliche Prozesse sind, dann sind diese Parallelen reiner Zufall. Aber Zufälle reihen sich normalerweise nicht vier-für-vier über klinische Neurologie, Psychopharmakologie und Psychotherapie hinweg auf. Die folgenden Kapitel werden jede Eigenschaft in Aktion zeigen.

Es gibt ein einfaches Experiment, das sich jetzt sofort durchführen lässt — nun ja, mit einem Freund, einer Gummihand, einem Kartonschirm und zwei Pinseln — und das demonstriert, wie leicht das Explizite Selbstmodell getäuscht werden kann. Es ist die Gummihand-Illusion, entwickelt von Matthew Botvinick und Jonathan Cohen, und sie ist einer der aufschlussreichsten Party-Tricks in der gesamten Neurowissenschaft.

Der Aufbau ist einfach. Man sitzt an einem Tisch mit einem Arm hinter einem Kartonschirm versteckt. Eine realistische Gummihand wird sichtbar platziert, ungefähr dort, wo die versteckte Hand wäre. Jemand streicht gleichzeitig über die Gummihand und die versteckte echte Hand mit zwei Pinseln, an derselben Stelle, mit derselben Geschwindigkeit. Nach ein oder zwei Minuten dieses synchronisierten Streichens passiert etwas Unheimliches: Man beginnt *zu fühlen*, wie der Pinsel über die Gummihand streicht. Nicht über die echte Hand, hinter dem Schirm. Über die falsche Hand vor den eigenen Augen.

Das Explizite Selbstmodell hat die Gummihand in das Körperschema integriert. Es hat die Eigentümerschaft neu zugewiesen — entschieden, dass die Gummihand Teil von „einem selbst" ist. Das Selbstmodell ist nicht festverdrahtet. Es ist gelernt. Es wird kontinuierlich auf Basis der besten verfügbaren Evidenz aktualisiert, und wenn die visuelle Evidenz (sehen, wie die Gummihand gestrichen wird) konsistent mit der taktilen Evidenz übereinstimmt (fühlen, wie die echte Hand gestrichen wird), zieht das ESM die rationale Schlussfolgerung: Diese Hand ist meine. Wenn jemand dann die Gummihand bedroht (einen Hammer darauf niedergehen lässt), zuckt man zusammen, fühlt einen Angstschub, die galvanische Hautreaktion schießt hoch. Für den Teil des Gehirns, der das „Ich" definiert, *ist* diese Hand die eigene.

Das ist kein Fehler. Das ist das Selbstmodell, das genau so funktioniert, wie es entworfen ist — ständig seine Körpergrenze auf Basis multimodaler sensorischer Korrelation aktualisierend. Es ist derselbe Mechanismus, der es Amputierten erlaubt, ein prothetisches Glied nach einer Nutzungsperiode als ihr eigenes zu „fühlen". Und es ist derselbe Mechanismus, der bei Asomatognosie zusammenbricht, wo Patienten die Eigentümerschaft ihrer tatsächlichen Gliedmaßen leugnen, und beim Alien-Hand-Syndrom, wo die Hand sich von selbst bewegt.

### Das Patchwork-Hologramm

Es gibt eine fünfte Eigenschaft der virtuellen Seite, die ihren eigenen Abschnitt verdient, weil sie etwas erklärt, das Neurowissenschaftler seit fast einem Jahrhundert verwirrt hat: warum Hirnschädigung Funktionen *graduell* verschlechtert, anstatt spezifische Erinnerungen zu löschen.

In den 1920er und 30er Jahren trainierte der Psychologe Karl Lashley Ratten, ein Labyrinth zu navigieren, und entfernte dann chirurgisch Stücke ihres Kortex, um herauszufinden, wo die Erinnerung gespeichert war. Er fand sie nie. Egal welches Stück er entfernte, die Ratten erinnerten sich noch an das Labyrinth. Was zählte, war *wie viel* Kortex er entfernte, nicht *welche Teile*. Entfernte er ein wenig, wurden die Ratten etwas schlechter. Entfernte er viel, wurden sie viel schlechter. Aber die Erinnerung war nie einfach *weg*, sauber herausgeschnitten wie eine Datei, die von einer Festplatte gelöscht wurde. Lashley verbrachte seine Karriere damit, das „Engramm" zu suchen — die physische Spur einer Erinnerung — und kam berühmterweise zu dem Schluss, dass es nicht zu existieren schien.

Er suchte nach der falschen Sache. Die Erinnerung war nicht *in* einem bestimmten Stück Kortex gespeichert, so wie eine Datei auf einem bestimmten Sektor einer Festplatte gespeichert ist. Sie war *über* das gesamte Netzwerk verteilt, in den Verbindungsgewichten zwischen Millionen von Neuronen. So funktionieren neuronale Netzwerke: Information sitzt nicht in irgendeinem einzelnen Knoten. Sie ist im Muster der Verbindungen zwischen allen von ihnen kodiert. Man kann nicht auf eine einzelne Synapse zeigen und sagen „hier ist das Labyrinth gespeichert", genauso wenig wie man auf ein einzelnes Pixel zeigen und sagen kann „hier ist der Film gespeichert."

Das ist im Wesentlichen eine holografische Eigenschaft. Nimmt man ein physisches Hologramm und halbiert es, erhält man nicht zwei Hälften des Bildes. Man erhält zwei Kopien des *vollständigen* Bildes, jede in niedrigerer Auflösung. Schneidet man es in Viertel, erhält man vier vollständige Bilder, noch verschwommener. Die Information in einem Hologramm ist über die gesamte Platte verteilt, sodass jedes Stück das ganze Bild enthält — nur mit weniger Detail.

Neuronale Netzwerke tun dasselbe. Trainiert man ein Netzwerk, Gesichter zu erkennen, und zerstört dann 10% seiner Verbindungen zufällig, vergisst es nicht 10% der Gesichter. Es wird etwas schlechter bei *allen* Gesichtern. Zerstört man 50%, wird es substanziell schlechter bei allem, erkennt aber immer noch etwas. Die Information ist über das gesamte Netzwerk verschmiert, was genau der Grund ist, warum Lashley das Engramm nicht finden konnte: Es war überall und nirgends.

Aber — und hier wird es interessant — das Gehirn ist *nicht* ein Hologramm. Es ist das, was ich ein *Patchwork-Hologramm* nenne. Innerhalb eines einzelnen funktionalen Areals (sagen wir, dem primären visuellen Kortex, ungefähr Brodmann-Areal 17) sind die kortikalen Säulen einander ähnlich, und Information wird holografisch gespeichert. Zerstört man ein paar Säulen, fällt es kaum auf. Das Areal ist lokal holografisch (ein Teil enthält das Ganze, in niedrigerer Auflösung).

Auf der globalen Ebene tun verschiedene Areale verschiedene Dinge. Der visuelle Kortex ist nicht austauschbar mit dem motorischen Kortex. Entfernt man den gesamten visuellen Kortex, verliert man das Sehen — es gibt kein verschwommenes Backup. Also ist das Gehirn lokal holografisch innerhalb jeder funktionalen Region, fraktal selbstähnlich in seiner kolumnaren Architektur, aber global *nicht* holografisch. Es ist ein Patchwork: Dutzende holografische Kacheln, zusammengenäht zu einem Kompositum, das als Ganzes entschieden nicht-holografisch ist.

Diese Patchwork-Struktur erklärt ein Muster, das in der klinischen Neurologie immer wieder auftaucht. Kleine Schlaganfälle und kleine Läsionen verursachen oft überraschend milde Defizite, weil innerhalb eines gegebenen kortikalen Areals das holografische Prinzip schützt. Das verbleibende Gewebe rekonstruiert die fehlende Information in niedrigerer Auflösung. Aber große Schlaganfälle, die ein gesamtes funktionales Areal auslöschen, verursachen katastrophale, spezifische Verluste (Blindheit, Lähmung, Aphasie), weil eine ganze Kachel aus dem Patchwork entfernt wurde und keine andere Kachel substituieren kann.

Es erklärt auch, warum Erinnerungen nicht einfach „aus der Existenz springen", wenn Neuronen sterben. Jeden Tag sterben Neuronen und Synapsen werden beschnitten. Wenn Erinnerungen wie Dateien auf einer Festplatte gespeichert wären, würde man erwarten, gelegentlich eine zu verlieren — eines Morgens aufzuwachen und die eigene Hochzeit vergessen zu haben, oder den Kindheitshund, oder den Geschmack von Kaffee. Das passiert nie. Stattdessen verblassen Erinnerungen allmählich, verlieren über Jahre Detail und Lebhaftigkeit. Das ist genau das, was ein holografisches Speichersystem vorhersagt: Degradation ist anmutig, proportional und global, niemals plötzlich, diskret oder lokal.

Das Patchwork-Hologramm ist der physische Grund, warum die Software-Eigenschaften, die ich oben beschrieben habe (besonders das Klonen) tatsächlich funktionieren. Teilt man das Gehirn in zwei Hälften, behält jede Hälfte eine degradierte, aber vollständige Kopie der Simulation, weil innerhalb jeder Hemisphäre das holografische Prinzip sicherstellt, dass jedes Stück das ganze Bild enthält. Die Simulation bricht nicht zusammen. Sie läuft nur in niedrigerer Auflösung.

---
