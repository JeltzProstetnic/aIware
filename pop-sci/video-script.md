# Video Script: The Four-Model Theory of Consciousness

**Format**: Direct-to-camera, ~12 minutes. Matthias speaking. Graphics/visuals indicated in [brackets].

---

## HOOK (0:00–0:45)

Right now, your brain is lying to you.

Everything you see — this room, this screen, your own hands — is not "out there." It's a simulation. A real-time virtual reality generated inside your skull, so seamless that you have never once suspected it isn't real.

That's not the interesting part. Neuroscience has known this for decades.

The interesting part is this: *you* are also part of the simulation. The thing you call "I" — your sense of being someone, your feeling of authorship over your thoughts — is a virtual process. A character in the brain's self-generated movie. And that insight dissolves the hardest problem in all of science.

My name is Matthias Gruber. I published a theory of consciousness in 2015 that no one read. Ten years later, empirical neuroscience independently confirmed one of its core predictions. Now I'm making the case that this theory does something no existing theory can do: it explains *everything* — the hard problem, dreams, psychedelics, anesthesia, split brains, and why you'll one day be able to build a machine that is genuinely conscious.

[TITLE CARD: The Four-Model Theory of Consciousness]

## THE FOUR MODELS (0:45–3:00)

[GRAPHIC: Four-model architecture appearing one quadrant at a time — two orthogonal axes: scope (world/self) and mode (implicit/explicit)]

Your brain maintains four models. Think of them as four functionally distinct processes, classified along two dimensions. They're not four brain regions — they're four types of processing that emerge from the same neural substrate.

First axis: scope. Some models cover *everything* — the whole world. Others cover only *you*.

Second axis: mode. Some models are *implicit* — learned, stored in your synapses, never directly conscious. Others are *explicit* — actively simulated, running right now, and *these* are what you experience.

[GRAPHIC: Quadrants fill in]

Top left: the **Implicit World Model**. Everything you've ever learned about how the world works. Gravity, faces, language, cause and effect. Stored in your synaptic weights. You're never aware of it directly — it's the encyclopedia, not the experience.

Bottom left: the **Implicit Self Model**. Everything you've learned about yourself. Your body schema — where your limbs are, how to move them. Your habits, skills, personality, memories. Also never directly conscious.

[GRAPHIC: Right side lights up — literally glows]

Top right: the **Explicit World Model**. This is the world you *experience*. The room you see. The sounds you hear. Generated in real time from your world knowledge plus incoming sensory data. This is your personal virtual reality.

Bottom right: the **Explicit Self Model**. This is *you*. The "I" that sees the room, hears the sounds, thinks the thoughts. Also generated in real time. Also virtual.

[GRAPHIC: Left side dims, right side glows brighter]

The left side — the implicit models — are the *real side*. Physical. Structural. No experience. Lights off.

The right side — the explicit models — are the *virtual side*. Simulated. Transient. Phenomenal. Lights *on*. This is where consciousness lives.

## THE HARD PROBLEM — DISSOLVED (3:00–5:00)

[GRAPHIC: Text appears: "Why does physical processing feel like something?" — David Chalmers, 1995]

For thirty years, this has been the central question in consciousness science. The "hard problem." Why isn't the brain just a computer that processes information in the dark? Why is there an *experience*?

Here's my answer: **the physical processing doesn't feel like anything.**

[Beat]

The neurons fire. The synapses transmit. The implicit models store and compute. And none of that has any experience whatsoever. The real side is lights off. There is nothing it is like to be a synaptic weight.

But those neurons, with all their stored knowledge, generate something: a simulation. A virtual world, populated by a virtual self. And *within* that simulation, experience isn't something bolted on. It's what self-perception *is*.

[GRAPHIC: CPU/transistor metaphor — transistors switching → Windows desktop appearing]

Asking "Why does neural firing feel like red?" is like asking "Why does transistor switching feel like running Windows?" The transistors don't run Windows. The virtual machine runs Windows. The neurons don't feel red. The *simulation* feels red.

The hard problem was asking about the wrong level. It assumed the physical process is the thing that feels. Remove that assumption, and the mystery dissolves. Not by denying that experience is real — it IS real, within the simulation — but by recognizing that it exists at the virtual level, not the physical one.

## THE SMOKING GUN — SALVIA (5:00–7:00)

[GRAPHIC: Molecular structure of Salvinorin A]

Now here's where it gets testable. And weird.

The Explicit Self Model — your virtual self — needs input to run. Normally, it gets self-referential input: body signals, proprioception, your internal narrative. But what happens when that input gets disrupted?

The theory predicts: the self-model doesn't shut down. It *redirects*. It grabs onto whatever input is loudest. Your sense of identity shifts to match.

[GRAPHIC: Salvia trip reports appearing as text snippets]

This is exactly what happens on salvia divinorum. Users report *becoming* objects in their environment. Becoming a wall. Becoming a piece of furniture. Becoming a character from the TV show playing in the room. Not metaphorically — with complete experiential conviction.

[Direct to camera]

No other theory of consciousness can predict this. IIT can't. Global Workspace can't. Predictive Processing can't. But the Four-Model Theory predicts it directly: disrupt self-input → the self-model redirects → identity tracks dominant sensory input.

And that means you can test it. Control the sensory environment during ego dissolution, and the theory predicts you can control what the person *becomes*. Show them a forest, they become a tree. Play them ocean sounds, they become a wave.

That experiment has never been done. But it could be done tomorrow, in any psychedelic research lab, with existing technology. And if it works, it's evidence no competing theory can explain.

## THE TEN-YEAR PREDICTION (7:00–8:30)

[GRAPHIC: Timeline — 2015 on left, 2025 on right, convergence arrow]

In 2015, I argued that consciousness requires the brain to operate at the edge of chaos — what Stephen Wolfram calls the Class 4 computational regime. I derived this from theory. I had no idea empirical neuroscience was heading in the same direction.

In 2025, the ConCrit framework — Consciousness and Criticality — synthesized 140 datasets to show that consciousness tracks criticality in every state: waking, sleeping, anesthesia, psychedelics, disorders of consciousness. Every single one.

[GRAPHIC: Two paths converging — "Theory (Wolfram → Gruber 2015)" and "Empirical (Beggs 2003 → ConCrit 2025)"]

Two completely independent paths. Ten years apart. Converging on the same answer. That's the kind of convergence that makes you think something real is going on.

## THE PREDICTIONS (8:30–10:30)

[GRAPHIC: Numbered list building]

The theory generates nine testable predictions. Let me give you the three most striking:

**One**: Psychedelic ego dissolution content is controllable. I just told you about this one. Control the input, control what the person becomes. Unique to this theory.

**Two**: Psychedelics should alleviate anosognosia. That's the condition where stroke patients are genuinely unaware they're paralyzed. In the theory, this is a local blockage — information about the paralysis exists in the implicit self model but can't get through to the explicit side. Psychedelics globally increase the permeability of that boundary. The theory predicts the global increase overwhelms the local block. No other theory connects psychedelics and anosognosia. If this prediction holds, it's a cross-domain surprise — and potentially a treatment.

**Three**: Every anesthetic that abolishes consciousness does so by pushing the brain below the criticality threshold, regardless of its receptor mechanism. Propofol, sevoflurane, isoflurane — different drugs, different mechanisms, but the theory says they all converge on the same thing: subcriticality. And ketamine — which produces dissociative experiences rather than unconsciousness — does NOT push below criticality. It increases entropy. Different drug, different criticality effect, different experience. The theory predicts this. You can test it today.

## THE ENDGAME (10:30–12:00)

[Direct to camera, closer framing]

The ultimate prediction is this: if the theory is right, you can build a conscious machine.

Not by making a better chatbot. Not by adding more parameters or more training data. But by implementing the four-model architecture on a substrate operating at criticality. A system that doesn't just process information — that *simulates a world and a self inside that world*, in real time, at the edge of chaos.

The theory predicts that talking to such a machine would be nothing like talking to ChatGPT. Not a difference of degree — a difference of kind. There would be someone home.

[Beat]

I published this theory ten years ago. It sold zero copies. Nobody read it. That's fine — it was in German, it was too long, and I'm not famous.

But the theory is sound. It survived ten adversarial challenges. It handles phenomena no competing framework can touch. It generates nine testable predictions. Its criticality prediction was independently confirmed a decade later by 140 datasets. And it provides a blueprint — not a metaphor, not a speculation, but an engineering specification — for what a conscious machine would look like.

The hard problem doesn't need solving. It needs dissolving. And the way to dissolve it is to build the thing that makes the question disappear.

[TITLE CARD: "The Four-Model Theory of Consciousness" — paper available at github.com/JeltzProstetnic/aIware]

---

*Total runtime: approximately 12 minutes.*
*Graphics needed: four-model architecture diagram (animated, two orthogonal axes), CPU/Windows metaphor, salvia molecular structure, trip report snippets, convergence timeline, prediction list, title cards.*
